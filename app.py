# app.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import seaborn as sns
import statsmodels.api as sm
import matplotlib.pyplot as plt
from statsmodels.stats.outliers_influence import variance_inflation_factor
import plotly.figure_factory as ff
from scipy.stats import chi2_contingency


from config import *
from data_loader import load_data_from_gsheet, merge_and_clean
from features import compute_disparities, add_disparity_index
from ui_components import filter_sidebar
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import umap.umap_ as umap
import plotly.figure_factory as ff
import scipy.stats as ss

# --- Constants ---
CATEGORICAL_FEATURES = [
    "Public/Private",
    "Degree of urbanization (Urban-centric locale)",
    "Institutional category"
]

# --- App Config ---
st.set_page_config(page_title="Diversity Disparity Dashboard", layout="wide")
st.title("üìä Faculty vs. Student Racial Disparity in U.S. Colleges")

# --- Cached Data Loaders ---
@st.cache_data(show_spinner="üì• Loading data from Google Sheets...", persist=True)
def get_merged_data():
    staff_df = load_data_from_gsheet(STAFF_SHEET_ID)
    student_df = load_data_from_gsheet(STUDENT_SHEET_ID)
    merged = merge_and_clean(student_df, staff_df)
    return merged

@st.cache_data(show_spinner="üîç Computing disparities...", persist=True)
def get_disparity_data(merged):
    merged = compute_disparities(merged, FACULTY_RACE_COLS, STUDENT_RACE_COLS)
    disparity_columns = [f"{race}_disparity" for race in FACULTY_RACE_COLS]
    merged["Disparity Index"] = merged[disparity_columns].abs().mean(axis=1)
    merged = add_disparity_index(merged, FACULTY_RACE_COLS)
    merged["endowment_per_fte"] = merged[
        "Endowment assets (year end) per FTE enrollment (FASB)"
    ].fillna(
        merged["Endowment assets (year end) per FTE enrollment (GASB)"]
    )
    return merged

# --- Load and Process Data ---
merged = get_merged_data()
merged = get_disparity_data(merged)

# --- Sidebar Filters ---
selected_state, selected_control, selected_degree, selected_urban = filter_sidebar(merged)

@st.cache_data(show_spinner="üîç Filtering dataset...", persist=True)
def get_filtered_df(merged, selected_state, selected_control, selected_degree, selected_urban):
    df = merged.copy()
    if selected_state != "All":
        df = df[df["State abbreviation"] == selected_state]
    if selected_control != "All":
        df = df[df["Public/Private"] == selected_control]
    if selected_degree != "All":
        df = df[df["Institutional category"] == selected_degree]
    if selected_urban != "All":
        df = df[df["Degree of urbanization (Urban-centric locale)"] == selected_urban]
    return df

filtered_df = get_filtered_df(merged, selected_state, selected_control, selected_degree, selected_urban)

# --- Tabs ---
tabs = st.tabs(["üìã Overview", "üß† PCA & UMAP", "üéØ Disparity Clusters", "üìà Regression", "üìä Correlation Matrix"])

# === üìã Overview ===
with tabs[0]:
    st.subheader("üìã Filtered Institutions with Racial Disparities")

    overview_columns = ["institution name_x"] + [f"{race}_disparity" for race in FACULTY_RACE_COLS] + [
        "State abbreviation", "Public/Private", "Total  enrollment", "Disparity Index"
    ]

    display_df = filtered_df[overview_columns].rename(columns={
        "institution name_x": "Institution",
        "State abbreviation": "State",
        **{f"{race}_disparity": f"{race} disparity" for race in FACULTY_RACE_COLS}
    })

    st.dataframe(display_df.reset_index(drop=True), use_container_width=True)

    st.markdown("""
    #### ‚ÑπÔ∏è How to Interpret Disparity
    - **Disparity = % of faculty ‚àí % of students** from the same racial group.
    - A **positive disparity** means the group is **overrepresented among faculty** compared to students.
    - A **negative disparity** means the group is **underrepresented among faculty**.
    - A value close to **zero** suggests relatively proportional representation.

    #### üìå Note on PCA/UMAP
    Racial disparity variables are **excluded** from the dimensionality reduction (PCA/UMAP) so that clusters represent institutional characteristics ‚Äî not outcomes.
    This helps ensure that disparities are analyzed as **results**, not drivers of clustering.
    """)


# === üß† PCA & UMAP ===
with tabs[1]:
    st.subheader("üß† PCA + UMAP + Clustering (Excludes Racial Disparities)")


    institutional_features = [
        "Total  enrollment",
        "Tuition and fees, 2023-24",
        "Percent admitted - total",
        "Admissions yield - total",
        "Student-to-faculty ratio",
        "Average salary equated to 9 months of full-time instructional staff - all ranks",
        "Percent of full-time first-time undergraduates awarded any financial aid",
        "Percent of full-time first-time undergraduates awarded federal, state, local or institutional grant aid",
        "Average amount of federal, state, local or institutional grant aid awarded",
        "endowment_per_fte"
    ]

    grad_features = ["Graduation rate, total cohort", "Graduation rate - Bachelor degree within 6 years, total"]

    selected_features = institutional_features + grad_features


    # Explicitly drop racial disparity columns
    drop_disparity_cols = [f"{race}_disparity" for race in FACULTY_RACE_COLS]
    all_features = selected_features + CATEGORICAL_FEATURES + ["institution name_x"]
    pca_data = filtered_df[all_features].drop(columns=[col for col in drop_disparity_cols if col in filtered_df.columns], errors="ignore").copy()

    column_thresh = 0.7 * len(pca_data)
    pca_data = pca_data.dropna(axis=1, thresh=column_thresh)
    pca_data = pca_data.replace([np.inf, -np.inf], np.nan)
    pca_data = pca_data.dropna()

    st.caption(f"üìä Institutions included in PCA/UMAP: {pca_data.shape[0]}")

    X_features = pd.get_dummies(pca_data.drop(columns=["institution name_x"]), drop_first=True)
    X_features = X_features.select_dtypes(include=[np.number])  # Only keep numeric
    X_features = X_features.replace([np.inf, -np.inf], np.nan).dropna()  # Drop inf/nan
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_features)

    n_clusters = st.slider("Number of clusters", min_value=2, max_value=10, value=4)
    pca_model = PCA(n_components=2)
    pca_result = pca_model.fit_transform(X_scaled)
    umap_result = umap.UMAP(random_state=42).fit_transform(X_scaled)
    cluster_labels = KMeans(n_clusters=n_clusters, random_state=42).fit_predict(X_scaled)

    pca_data = pca_data.reset_index(drop=True)
    pca_data["PCA_1"] = pca_result[:, 0]
    pca_data["PCA_2"] = pca_result[:, 1]
    pca_data["UMAP_1"] = umap_result[:, 0]
    pca_data["UMAP_2"] = umap_result[:, 1]
    pca_data["Cluster"] = cluster_labels

    st.markdown("""
    #### üîé PCA Explained
    - PCA projects data onto axes that explain the most variance.
    - UMAP preserves more local structure and neighborhood proximity.
    - Clustering (KMeans) groups institutions with similar profiles.
    """)

    st.write("##### üî¢ Variance Explained")
    explained_df = pd.DataFrame({
        "Component": ["PC1", "PC2"],
        "Variance Explained": pca_model.explained_variance_ratio_
    })
    st.dataframe(explained_df)

    st.write("##### üîç Top Features Contributing to PC1/PC2")
    components_df = pd.DataFrame(pca_model.components_, columns=X_features.columns, index=["PC1", "PC2"])
    st.write("**PC1 Top Features:**")
    st.dataframe(components_df.loc["PC1"].sort_values(ascending=False).head(10))
    st.write("**PC2 Top Features:**")
    st.dataframe(components_df.loc["PC2"].sort_values(ascending=False).head(10))

    st.write("### üìå PCA Scatter Plot")
    fig1 = px.scatter(
        pca_data,
        x="PCA_1", y="PCA_2",
        color="Cluster",
        hover_data=["institution name_x"],
        title="PCA Projection Colored by Cluster"
    )
    st.plotly_chart(fig1, use_container_width=True)

    st.write("### üìå UMAP Scatter Plot")
    fig2 = px.scatter(
        pca_data,
        x="UMAP_1", y="UMAP_2",
        color="Cluster",
        hover_data=["institution name_x"],
        title="UMAP Projection Colored by Cluster"
    )
    st.plotly_chart(fig2, use_container_width=True)

# === üéØ Disparity Clusters ===
with tabs[2]:
    st.subheader("üéØ Explore Racial Disparity by Cluster")

    disparity_races = {
        "Asian": "Asian_disparity",
        "Black": "Black_disparity",
        "Hispanic": "Hispanic_disparity",
        "White": "White_disparity",
        "Two or more": "Two or more_disparity",
        "Native American": "Native American_disparity",
        "Pacific Islander": "Pacific Islander_disparity"
    }

    all_disparities = filtered_df[[f"{r}_disparity" for r in FACULTY_RACE_COLS]].stack()
    vmin = np.percentile(all_disparities, 1)
    vmax = np.percentile(all_disparities, 99)
    abs_max = max(abs(vmin), abs(vmax))
    if abs_max == 0 or np.isnan(abs_max):
        abs_max = 1

    selected_race_label = st.radio("Choose a race to visualize:", list(disparity_races.keys()), horizontal=True)
    race_column = disparity_races[selected_race_label]

    st.subheader(f"{selected_race_label} Disparity by Cluster")
    plot_df = filtered_df[["institution name_x", race_column]].copy()
    plot_df = plot_df.dropna()
    plot_df = plot_df.merge(pca_data[["institution name_x", "PCA_1", "PCA_2", "UMAP_1", "UMAP_2", "Cluster"]], on="institution name_x", how="inner")

    fig_pca = px.scatter(
        plot_df,
        x="PCA_1", y="PCA_2",
        color=race_column,
        color_continuous_scale=["red", "lightgrey", "blue"],
        range_color=[-abs_max, abs_max],
        hover_data=["institution name_x", "Cluster"],
        title=f"PCA View ‚Äì {selected_race_label} Disparity"
    )
    st.plotly_chart(fig_pca, use_container_width=True)

    fig_umap = px.scatter(
        plot_df,
        x="UMAP_1", y="UMAP_2",
        color=race_column,
        color_continuous_scale=["red", "lightgrey", "blue"],
        range_color=[-abs_max, abs_max],
        hover_data=["institution name_x", "Cluster"],
        title=f"UMAP View ‚Äì {selected_race_label} Disparity"
    )
    st.plotly_chart(fig_umap, use_container_width=True)

# === üìà Regression ===
with tabs[3]:
    st.subheader("üìà Linear Regression & Correlation Analysis")

    selected_race = st.selectbox("Choose a race for disparity outcome:", list(FACULTY_RACE_COLS.keys()))
    disparity_var = f"{selected_race}_disparity"

    reg_features = [
        "Total  enrollment",
        "Tuition and fees, 2023-24",
        "Percent admitted - total",
        "Admissions yield - total",
        "Student-to-faculty ratio",
        "Average salary equated to 9 months of full-time instructional staff - all ranks",
        "Percent of full-time first-time undergraduates awarded any financial aid",
        "endowment_per_fte"
    ]

    reg_df = filtered_df[[disparity_var] + reg_features + ["Public/Private"]].dropna()
    reg_df = pd.get_dummies(reg_df, columns=["Public/Private"], drop_first=True)

    public_private_dummies = [col for col in reg_df.columns if col.startswith("Public/Private_")]
    reg_features += public_private_dummies

    st.write("### üîç Correlation with Disparity")
    corr_matrix = reg_df.corr()[[disparity_var]].drop(index=disparity_var)
    st.dataframe(corr_matrix.style.format("{:.2f}"))

    fig, ax = plt.subplots()
    sns.heatmap(corr_matrix, annot=True, cmap="magma", center=0)
    st.pyplot(fig)

# === üßÆ Variance Inflation Factor (VIF) ===
    st.write("### üßÆ Variance Inflation Factor (VIF)")

    # Ensure all features used in VIF calculation are numeric and valid
    X_vif = sm.add_constant(reg_df[reg_features])
    X_vif = X_vif.select_dtypes(include=[np.number])  # Drop non-numeric columns
    X_vif = X_vif.replace([np.inf, -np.inf], np.nan).dropna()  # Remove inf/nan rows

    # Compute VIFs
    vif_df = pd.DataFrame()
    vif_df["Feature"] = X_vif.columns
    vif_df["VIF"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]

    st.dataframe(vif_df)

    st.write("### üßÆ Linear Regression Results")
# --- Calculate Disparities ---
    merged["faculty_total"] = merged["Grand total"]
    for race in FACULTY_RACE_COLS:
        merged[f"{race}_faculty_pct"] = (merged[FACULTY_RACE_COLS[race]] / merged["faculty_total"]) * 100
        merged[f"{race}_student_pct"] = merged[STUDENT_RACE_COLS[race]]
        merged[f"{race}_disparity"] = merged[f"{race}_faculty_pct"] - merged[f"{race}_student_pct"]

    # --- Regression Model ---

    # Using selected race for disparity and graduation rate

    disparity_column = f"{selected_race}_disparity"

    # Gracefully handle graduation rate column naming inconsistencies
    grad_rate_column_options = {
        "Asian": ["Graduation rate, Asian", "Graduation rate, Asian/Native Hawaiian/Other Pacific Islander"],
        "Black": ["Graduation rate, Black, non-Hispanic", "Graduation rate, Black"],
        "Hispanic": ["Graduation rate, Hispanic", "Graduation rate, Hispanic or Latino"],
        "White": ["Graduation rate, White, non-Hispanic", "Graduation rate, White"],
        "Two or more": ["Graduation rate, two or more races"],
        "Native American": ["Graduation rate, American Indian or Alaska Native"],
        "Pacific Islander": ["Graduation rate, Native Hawaiian or Other Pacific Islander"]
    }

    grad_rate_column = None
    for col in grad_rate_column_options.get(selected_race, []):
        if col in merged.columns:
            grad_rate_column = col
            break

    if grad_rate_column is None:
        st.error(f"‚ùå Graduation rate column not found for: '{selected_race}'")
        st.stop()

    # Independent variable
    X = merged[[disparity_column]].dropna()
    y = merged[grad_rate_column].dropna()

    # Align indices
    X, y = X.align(y, join='inner', axis=0)

    # Add intercept
    X = sm.add_constant(X)

    # Fit model
    model = sm.OLS(y, X).fit()

    # Display regression results
    st.subheader(f"üìà Regression Model: Disparity vs. Graduation Rate ({selected_race})")
    st.write(model.summary())

    # Plot
    plt.figure(figsize=(10, 6))
    plt.scatter(X[disparity_column], y, label="Data", color="blue", alpha=0.5)
    plt.plot(X[disparity_column], model.predict(X), label="Fitted Line", color="red", linewidth=2)
    plt.title(f"Disparity vs. Graduation Rate ({selected_race}) - Regression Line")
    plt.xlabel(f"Faculty-Student Disparity ({selected_race})")
    plt.ylabel(f"Graduation Rate ({selected_race})")
    plt.legend()
    st.pyplot(plt)


# --- üìä Interactive Correlation Matrix ---
with tabs[4]:
    st.subheader("üìà Interactive Correlation Matrix of Disparities vs. Graduation Rates")

    categorical_features = [
        "Public/Private",
        "Degree of urbanization (Urban-centric locale)",
        "Institutional category"
    ]

    numerical_features = [
        "Total  enrollment",
        "Tuition and fees, 2023-24",
        "Percent admitted - total",
        "Graduation rate, total cohort"
    ]

    numerical_features += [col for col in GRAD_RATE_COLS if col in merged.columns]

    if "Graduation rate, Black" in merged.columns and "Graduation rate, Black, non-Hispanic" not in merged.columns:
        numerical_features.append("Graduation rate, Black")
    if "Graduation rate, White" in merged.columns and "Graduation rate, White, non-Hispanic" not in merged.columns:
        numerical_features.append("Graduation rate, White")

    numerical_features += [f"{r}_disparity" for r in FACULTY_RACE_COLS if f"{r}_disparity" in merged.columns]

    all_features = numerical_features + categorical_features
    available_features = [col for col in all_features if col in merged.columns]

    row_thresh = int(0.7 * len(available_features))
    corr_df = merged[available_features].dropna(thresh=row_thresh)

    if corr_df.empty:
        st.error("‚ö†Ô∏è Not enough data after threshold filtering. Please adjust missing data settings.")
        st.stop()

    corr_df_encoded = pd.get_dummies(
        corr_df,
        columns=[col for col in categorical_features if col in corr_df.columns],
        drop_first=True
    )
    corr_df_encoded = corr_df_encoded.replace([np.inf, -np.inf], np.nan)

    disparity_columns = []
    grad_rate_columns = []
    for race, options in grad_rate_column_options.items():
        grad_col = next((col for col in options if col in corr_df_encoded.columns), None)
        disparity_col = f"{race}_disparity"
        if grad_col:
            if grad_col not in grad_rate_columns:
                grad_rate_columns.append(grad_col)
        else:
            st.warning(f"Graduation rate data is missing for the {race} group.")
        if disparity_col in corr_df_encoded.columns:
            if disparity_col not in disparity_columns:
                disparity_columns.append(disparity_col)
        else:
            st.warning(f"Disparity data is missing for the {race} group.")

    if corr_df_encoded.shape[0] < 2 or not grad_rate_columns or not disparity_columns:
        st.warning("Not enough data available to compute the correlation matrix.")
    else:
        grad_rate_disparity_columns = grad_rate_columns + disparity_columns
        numeric_cols = corr_df_encoded[grad_rate_disparity_columns].select_dtypes(include=[np.number])
        corr_matrix = numeric_cols.corr()
        try:
            corr_matrix_selected = corr_matrix.loc[grad_rate_columns, disparity_columns]
        except KeyError as e:
            st.error(f"‚ùå Error selecting correlation sub-matrix: {e}")
            st.stop()

        rounded_values = np.round(corr_matrix_selected.values, 2)
        x_labels = list(corr_matrix_selected.columns)
        y_labels = list(corr_matrix_selected.index)

        try:
            fig_corr = ff.create_annotated_heatmap(
                z=rounded_values,
                x=x_labels,
                y=y_labels,
                colorscale="YlGnBu",
                showscale=True,
                colorbar_title="Correlation Coefficient",
                annotation_text=[[f"{val:.2f}" for val in row] for row in rounded_values]
            )
            for i, ann in enumerate(fig_corr.layout.annotations):
                row = i // len(x_labels)
                col = i % len(x_labels)
                val = rounded_values[row][col]
                ann.font.color = "black" if abs(val) < 0.25 else "white"

            fig_corr.update_layout(
                title="Interactive Correlation Matrix of Disparities vs. Graduation Rates",
                xaxis_title="Faculty-Student Disparity",
                yaxis_title="Graduation Rate",
                width=800,
                height=600,
                template="plotly_dark"
            )
            st.plotly_chart(fig_corr, use_container_width=True, key="heatmap_disparity_grad_1")
        except Exception as e:
            st.error(f"‚ùå Error rendering correlation heatmap: {e}")

    st.markdown("""
    The interactive correlation matrix above shows the relationships between racial disparities in faculty-student composition and graduation rates for each racial group. You can hover over each cell to see the correlation coefficient. Positive correlations indicate that greater disparities in faculty diversity are associated with higher graduation rates, while negative correlations suggest the opposite. This matrix helps understand how faculty-student diversity disparities may influence academic success rates across different racial and ethnic groups.
    """)


    # ‚úÖ Select relevant numeric data
    grad_rate_disparity_columns = disparity_columns + grad_rate_columns
    numeric_cols = corr_df_encoded[grad_rate_disparity_columns].select_dtypes(include=[np.number])

    # ‚úÖ Correlation matrix
    corr_matrix = numeric_cols.corr()
    corr_matrix_selected = corr_matrix.loc[grad_rate_columns, disparity_columns]
    rounded_values = np.round(corr_matrix_selected.values, 2)

    x_labels = list(corr_matrix_selected.columns)
    y_labels = list(corr_matrix_selected.index)

    # ‚úÖ Plot with dynamic text contrast
    try:
        fig_corr = ff.create_annotated_heatmap(
        z=rounded_values,
        x=x_labels,
        y=y_labels,
        colorscale='YlGnBu',
        showscale=True,
        colorbar_title="Correlation Coefficient",
        annotation_text=[[f"{val:.2f}" for val in row] for row in rounded_values]
        )

        # üîÅ Dynamically adjust font color for contrast based on value
        for i, ann in enumerate(fig_corr.layout.annotations):
            # Convert flat index to 2D indices
            row = i // len(x_labels)
            col = i % len(x_labels)
            val = rounded_values[row][col]

            # Adjust contrast: light background ‚Üí dark text, and vice versa
            ann.font.color = 'black' if abs(val) < 0.25 else 'white'

        # Layout settings
        fig_corr.update_layout(
            title="Interactive Correlation Matrix of Disparities vs. Graduation Rates",
            xaxis_title="Faculty-Student Disparity",
            yaxis_title="Graduation Rate",
            width=800,
            height=600,
            template="plotly_dark"
        )

        st.plotly_chart(fig_corr, use_container_width=True, key="heatmap_disparity_grad_2")

    except Exception as e:
        st.error(f"‚ùå Error rendering correlation heatmap: {e}")


    st.text("The interactive correlation matrix above shows the relationships between racial disparities in faculty-student composition and graduation rates for each racial group. You can hover over each cell to see the correlation coefficient. Positive correlations indicate that greater disparities in faculty diversity are associated with higher graduation rates, while negative correlations suggest the opposite. This matrix helps understand how faculty-student diversity disparities may influence academic success rates across different racial and ethnic groups.")

    def cramers_v(cat1, cat2):
        confusion_matrix = pd.crosstab(cat1, cat2)
        chi2, p, dof, expected = ss.chi2_contingency(confusion_matrix)
        n = confusion_matrix.sum().sum()
        return np.sqrt(chi2 / (n * (min(confusion_matrix.shape) - 1)))

    def cramers_v_matrix(df, categorical_columns):
        cramers_v_matrix = pd.DataFrame(index=categorical_columns, columns=categorical_columns)
        for col1 in categorical_columns:
            for col2 in categorical_columns:
                if col1 != col2:
                    cramers_v_matrix.loc[col1, col2] = cramers_v(df[col1], df[col2])
                else:
                    cramers_v_matrix.loc[col1, col2] = 1.0
        return cramers_v_matrix

    numeric_df = corr_df_encoded[[col for col in numerical_features if col in corr_df_encoded.columns]].copy()
    pearson_corr_matrix = numeric_df.corr()

    cramers_v_corr_matrix = cramers_v_matrix(corr_df_encoded, [col for col in categorical_features if col in corr_df_encoded.columns])

    st.write("### üìä Pearson Correlation Matrix (Numeric Features)")
    st.dataframe(pearson_corr_matrix.style.format("{:.2f}"))

    z_vals = pearson_corr_matrix.values.round(2)
    font_colors = [['black' if abs(val) < 0.5 else 'white' for val in row] for row in z_vals]

    fig_pearson = ff.create_annotated_heatmap(
        z=pearson_corr_matrix.values.round(2),
        x=list(pearson_corr_matrix.columns),
        y=list(pearson_corr_matrix.index),
        colorscale='PiYG',
        showscale=True,
        colorbar_title="Pearson Correlation",
    )
    for i, ann in enumerate(fig_pearson.layout.annotations):
        val = float(ann.text)
        if abs(val) < 0.5:
            ann.font.color = 'black'
        else:
            ann.font.color = 'white'
    fig_pearson.update_layout(
        title="Pearson Correlation Matrix (Numeric Features)",
        xaxis_title="Numeric Features",
        yaxis_title="Numeric Features",
        width=800,
        height=900,
        template="plotly_dark"
    )
    st.plotly_chart(fig_pearson, use_container_width=True, key="fig_corr_pearson")

ite("### üìä Cram√©r's V Correlation Matrix (Categorical Features)")

if not cramers_v_corr_matrix.empty:
    st.dataframe(cramers_v_corr_matrix.style.format("{:.2f}"))

    fig_cramers_v = ff.create_annotated_heatmap(
        z=cramers_v_corr_matrix.values.astype(float).round(2),
        x=list(cramers_v_corr_matrix.columns),
        y=list(cramers_v_corr_matrix.index),
        colorscale='YlGnBu',
        showscale=True,
        colorbar_title="Cram√©r's V"
    )
    fig_cramers_v.update_layout(
        title="Cram√©r's V Correlation Matrix (Categorical Features)",
        xaxis_title="Categorical Features",
        yaxis_title="Categorical Features",
        width=800,
        height=600,
        template="plotly_dark"
    )
    st.plotly_chart(fig_cramers_v, use_container_width=True, key="fig_corr_cramers")
else:
    st.warning("‚ö†Ô∏è Not enough categorical data available to compute Cram√©r's V correlation matrix.")

st.text("""
The Pearson correlation matrix shows the relationships between numeric variables (e.g., faculty-student disparity, graduation rate, etc.).
The Cram√©r's V matrix shows the strength of association between categorical features (e.g., institution type, urbanization degree).
You can hover over the cells to see the exact values for each correlation.
""")
    st.wr       